% !TeX document-id = {4719ec8f-70f7-4005-9222-7d90db5fa2e2}
% !TeX spellcheck = en-US
% !TeX encoding = utf8
% !TeX program = pdflatex
% !BIB program = biber
% -*- coding:utf-8 mod:LaTeX -*-


% vv  scroll down to line 200 for content  vv


\let\ifdeutsch\iffalse
\let\ifenglisch\iftrue
\input{pre-documentclass}
\documentclass[
  % fontsize=11pt is the standard
  a4paper,  % Standard format - only KOMAScript uses paper=a4 - https://tex.stackexchange.com/a/61044/9075
  twoside,  % we are optimizing for both screen and two-sided printing. So the page numbers will jump, but the content is configured to stay in the middle (by using the geometry package)
  bibliography=totoc,
  %               idxtotoc,   %Index ins Inhaltsverzeichnis
  %               liststotoc, %List of X ins Inhaltsverzeichnis, mit liststotocnumbered werden die Abbildungsverzeichnisse nummeriert
  headsepline,
  cleardoublepage=empty,
  parskip=half,
  %               draft    % um zu sehen, wo noch nachgebessert werden muss - wichtig, da Bindungskorrektur mit drin
  draft=false
]{scrbook}
\input{config}


\usepackage[
  title={},
  author={Lars K.},
  type=bachelor,
  institute=iaas, % or other institute names - or just a plain string using {Demo\\Demo...}
  course={Medieninformatik},
  examiner={Prof.\ Dr.\ Uwe Fessor},
  supervisor={Dipl.-Inf.\ Roman Tiker,\\Dipl.-Inf.\ Laura Stern,\\Otto Normalverbraucher,\ M.Sc.},
  startdate={July 5, 2018},
  enddate={January 5, 2019}
]{scientific-thesis-cover}

\input{acronyms}

\makeindex

\begin{document}

%tex4ht-Konvertierung verschönern
\iftex4ht
  % tell tex4ht to create pictures also for formulas starting with '$'
  % WARNING: a tex4ht run now takes forever!
  \Configure{$}{\PicMath}{\EndPicMath}{}
  %$ % <- syntax highlighting fix for emacs
  \Css{body {text-align:justify;}}

  %conversion of .pdf to .png
  \Configure{graphics*}
  {pdf}
  {\Needs{"convert \csname Gin@base\endcsname.pdf
      \csname Gin@base\endcsname.png"}%
    \Picture[pict]{\csname Gin@base\endcsname.png}%
  }
\fi

%\VerbatimFootnotes %verbatim text in Fußnoten erlauben. Geht normalerweise nicht.

\input{commands}
\pagenumbering{arabic}
\Titelblatt

%Eigener Seitenstil fuer die Kurzfassung und das Inhaltsverzeichnis
\deftriplepagestyle{preamble}{}{}{}{}{}{\pagemark}
%Doku zu deftriplepagestyle: scrguide.pdf
\pagestyle{preamble}
\renewcommand*{\chapterpagestyle}{preamble}



%Kurzfassung / abstract
%auch im Stil vom Inhaltsverzeichnis
\section*{Abstract}

<Short summary of the thesis>

\cleardoublepage

%Solely for German courses of study
\section*{Kurzfassung}

<Kurzfassung der Arbeit>

\cleardoublepage


% BEGIN: Verzeichnisse

\iftex4ht
\else
  \microtypesetup{protrusion=false}
\fi

%%%
% Literaturverzeichnis ins TOC mit aufnehmen, aber nur wenn nichts anderes mehr hilft!
% \addcontentsline{toc}{chapter}{Literaturverzeichnis}
%
% oder zB
%\addcontentsline{toc}{section}{Abkürzungsverzeichnis}
%
%%%

%Produce table of contents
%
%In case you have trouble with headings reaching into the page numbers, enable the following three lines.
%Hint by http://golatex.de/inhaltsverzeichnis-schreibt-ueber-rand-t3106.html
%
%\makeatletter
%\renewcommand{\@pnumwidth}{2em}
%\makeatother
%
\tableofcontents

% Bei einem ungünstigen Seitenumbruch im Inhaltsverzeichnis, kann dieser mit
% \addtocontents{toc}{\protect\newpage}
% an der passenden Stelle im Fließtext erzwungen werden.

\listoffigures
\listoftables

%Wird nur bei Verwendung von der lstlisting-Umgebung mit dem "caption"-Parameter benoetigt
%\lstlistoflistings
%ansonsten:
\ifdeutsch
  \listof{Listing}{Verzeichnis der Listings}
\else
  \listof{Listing}{List of Listings}
\fi

%mittels \newfloat wurde die Algorithmus-Gleitumgebung definiert.
%Mit folgendem Befehl werden alle floats dieses Typs ausgegeben
\ifdeutsch
  \listof{Algorithmus}{Verzeichnis der Algorithmen}
\else
  \listof{Algorithmus}{List of Algorithms}
\fi
%\listofalgorithms %Ist nur für Algorithmen, die mittels \begin{algorithm} umschlossen werden, nötig

% Abkürzungsverzeichnis
\printnoidxglossaries

\iftex4ht
\else
  %Optischen Randausgleich und Grauwertkorrektur wieder aktivieren
  \microtypesetup{protrusion=true}
\fi

% END: Verzeichnisse


% Headline and footline
\renewcommand*{\chapterpagestyle}{scrplain}
\pagestyle{scrheadings}
\pagestyle{scrheadings}
\ihead[]{}
\chead[]{}
\ohead[]{\headmark}
\cfoot[]{}
\ofoot[\usekomafont{pagenumber}\thepage]{\usekomafont{pagenumber}\thepage}
\ifoot[]{}


%% vv  scroll down for content  vv %%































%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% Main content starts here
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\chapter{Introduction}

This thesis starts with \cref{chap:k2}.

We can also typeset \verb|<text>verbatim text</text>|.
Backticks are also rendered correctly: \verb|`words in backticks`|.
With the growing capabilities of AI in recent years its usage has become more widely adopted with some sources claiming 280 million global users in 2024 \cite{AI-users} with projections of up to 1 billion users in 2030.

Besides the very popular Llms there are the generative models which have adapted a wide variety of use cases such as music, video and image generation. 

For the purpose of this thesis we will regard image generation models. These have made great advances in the past years and the best models such as mid-journey\cite{midjourney}, stable diffusion \cite{stable-diffusion}, or even GPT-4o \cite{GPT-4o} are capable of creating impressive images that are capable of creating photo realistic images and paintings in many other art styles and art forms they are limited by very little and allow people to explore their creativity. 

The most common approach in working with am image generation models is providing a textual prompt from which the model then generates an image, other prompt medias include pictures or sounds. With this approach the problem arises that the user doesn't know how the model will process the prompt exactly. For the average user the model is a black box and getting the desired image by tweaking the prompt can be a challenging and sometimes feel arbitrary, the goal here be to understand how changes in the prompt impact the generated picture. 
\chapter{Background}
\label{chap:k2}
This section serves as an introduction to topics, concepts and techniques that are relevant to understanding this thesis, introducing the topics of generative models, diffusion models Large-Language-Models (LLMs), prompt engineering, vectorization of images, vector dimensionality reduction, pixel based comparison and visualization techniques. 
\section{Generative models}
%strutcure
%Definition: Learning data distributions to generate novel samples
%Key distinction from discriminative models

%Broad applications: image synthesis, text generation, audio, video

Generative models are a relatively recent phenomenon in the field of AI, they aim to create new unseen data that fits the data they have been trained upon. The most prominent of them are image generation models with the first models capable of generating complex images emerging in 2013 they are called VAE (variational autoencoders) named after the architecture they are based on (Auto-Encoding Variational Bayes) and work by making stochastic sampling differentiable \cite{kingma2022autoencodingvariationalbayes}, however early adaptations resulted in blury and low resolution images.
Then in 2014 goodfellow et. all {goodfellow2014generativeadversarialnetworks} proposed a new process for estimating generative models using an adverserial approach, this is realized by using a two part architecture in training, a generator and a discriminator both neural networks. The generator outputs a sample from noise and the discriminator tries to classify whether that sample is a from a real data distribution or generated based on the result of the discriminator the generators weights are adjusted to result in a less distinguishable output. This approach results in more realistic higher quality images, since the generator is trained to "fool" the discriminator into thinking its output is real. 

In 2017 Vaswani et al pusblished their breakthrough paper \verb|“Attention Is All You Need”| \cite{vaswani2023attentionneed} introducing transformer architecture for AI %self-attention, positional encoding, encoder–decoder structure 
originally intended for sequence-to-sequence tasks their adaptation too generative AI was very successful, with early models using transformer architecture like GPT-1 \cite{GPT-1} and BERT \cite{devlin2019bertpretrainingdeepbidirectional} being quite capable for their respective tasks. However early transformer models for image generation such as Image Transformer \cite{parmar2018imagetransformer} struggeled with producing high quality images, while later attempts and hybrid architecture led to better performance generating images. Then in 2020 Ho et. al published their landmark paper "Denoising Diffusion Probabilistic Models" where they adpated diffusion models for image generation running on transformers.
Subsequent improvements of the approach make diffsion models the state-of-the-art for image generation, which is why they were used for image generation in this work. %add reference to stable diffusion or models being used for live generation

\section{LLMs}
Large-Language-Models (LLMs) have emerged in the field of natural language processing (nlp) but have since transcended their original purpose, most of them function by predicting the next token utilizing a transformer architecture and large scale pre-training on massive amounts of data they are able to achieve impressive results text generation and summarization to translation, reasoning, and dialogue. Their big breakthrough was in 2020 with Brown et al. publishing GPT-3 \cite{brown2020languagemodelsfewshotlearners} first showing  that scaling the number of parameters and training data substantially improves performance. However despite their impressive capabilities LLMs are faced with several drawbacks, they are computationally expensive requiring large resource hungry data centers to train and service request at scale, additionally they may show bias or inaccuracy in their responses depending on the underlying training data, which makes sourcing quality data at the required scale a major challenge LLM developers face. Another negative is their non applicability in safety critical environments due to hallucination, where the model generates plausible but incorrect outputs.

\section{prompt engineering}
In order to use the LLMs introduced in the last section we need to "prompt" them that means entering a text or an image with instructions for the LLM. However what and how we type the prompt is important for the performance of the model as zhang et al. \cite{zhang2025understandingrelationshippromptsresponse} and li et al. \cite{li2024effectsdifferentpromptsquality} have shown for their respective selected tasks. This importance of the prompt has created a whole new field of research called "prompt engineering" where people are trying to find techniques and tricks to improve the LLM output or even get past certain restrictions. 
To achieve accurate results some prompt engineering principles were also employed in this thesis.

\section{vectorization of images}
Comparing images is an old and non-trivial problem that is also afflicted by subjectivity, as humans might rate different images as more similar or dissimilar based on individual factors. Human evaluation also takes longer and is more costly which is why a mathematical method is crucial. 
One way is to transform an image into something with many pre-existing comparison methods such as a vector where mathematical similarity measurements are well established. There are several ways to turn an image into a vector such as the "classical" approach where feature extraction is hand-engineered such as SIFT \cite{inbook}, however due to greater generalizability, automatic feature extraction and usually better performance methods using specifically trained machine learning models are generally preferred. Which was also the case in this thesis, where the Img2Vec library \cite{patel2019img2vec} was utilized.

\section{vector dimensonality reduction}




LaTeX hints are provided in \cref{chap:latexhints}.

\blinddocument

\chapter{Related Work}

Describe relevant scientific literature related to your work.

\chapter{Conclusion and Outlook}
\label{chap:zusfas}

\section*{Outlook}

\printbibliography

All links were last followed on March 17, 2018.

\appendix
\input{latexhints-english}

\pagestyle{empty}
\renewcommand*{\chapterpagestyle}{empty}
\Versicherung
\end{document}
